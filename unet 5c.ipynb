{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os;\n",
    "import sys;\n",
    "import random;\n",
    "import json\n",
    "\n",
    "import numpy as np;\n",
    "import cv2;\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras;\n",
    "import openslide\n",
    "import imutils\n",
    "\n",
    "import pylab\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from skimage.data import astronaut\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import sobel;\n",
    "import skimage\n",
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "\n",
    "\n",
    "import skimage.filters as filters\n",
    "import skimage.draw as draw\n",
    "import skimage.color as color\n",
    "\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "60\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "datapath=\"./gland/\";\n",
    "\n",
    "train_ids=[];\n",
    "test_ids=[];\n",
    "test_ids2=[];\n",
    "\n",
    "files=os.listdir(datapath)\n",
    "for i in files:\n",
    "    i = i.replace(\"_anno.bmp\",\"\").replace(\".bmp\",\"\");\n",
    "    if i.startswith(\"testB\"):\n",
    "        test_ids2.append(i)\n",
    "        \n",
    "    elif i.startswith(\"train\"):\n",
    "        train_ids.append(i)\n",
    "        \n",
    "    elif i.startswith(\"testA\"):\n",
    "        test_ids.append(i)\n",
    "        \n",
    "\n",
    "train_ids=list(set(train_ids))\n",
    "test_ids=list(set(test_ids))\n",
    "test_ids2=list(set(test_ids2))\n",
    "\n",
    "\n",
    "print(len(train_ids))\n",
    "print(len(test_ids))\n",
    "print(len(test_ids2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen(keras.utils.Sequence):\n",
    "    def __init__(self,ids,batch_size=0,image_size=(256,256)):\n",
    "        self.ids=ids;\n",
    "        \n",
    "        self.batch_size =batch_size;\n",
    "        self.image_size = image_size;\n",
    "        \n",
    "        \n",
    "    def __load__(self,id_name):\n",
    "        \n",
    "        path=datapath;\n",
    "        \n",
    "        image_path = os.path.join(path,id_name)+\".bmp\";\n",
    "        \n",
    "        image = cv2.imread(image_path);\n",
    "        \n",
    "        mask_path= os.path.join(path,id_name)+\"_anno.bmp\";\n",
    "        mask = cv2.imread(mask_path,-1);\n",
    "        \n",
    "        thresh =0.5\n",
    "        mask = cv2.threshold(mask, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "        \n",
    "        image =  cv2.normalize(image, None, 0, 255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC3)\n",
    "        \n",
    "        image = cv2.resize(image,self.image_size);\n",
    "        \n",
    "        \n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY);\n",
    "        \n",
    "        \n",
    "        deep=cv2.CV_64F;\n",
    "        x=cv2.Sobel(gray,deep,1,0)\n",
    "        y=cv2.Sobel(gray,deep,0,1)\n",
    "\n",
    "        absx= cv2.convertScaleAbs(x)\n",
    "        absy= cv2.convertScaleAbs(y)\n",
    "\n",
    "        dist = cv2.addWeighted(absx,0.5,absy,0.5,0)\n",
    "        \n",
    "        lap = cv2.Laplacian(gray,deep,3)\n",
    "        lap = cv2.convertScaleAbs(lap);\n",
    "        \n",
    "        result=np.zeros((self.image_size[0],self.image_size[1],5))\n",
    "        result[:,:,0:3]=image;\n",
    "        result[:,:,3]=dist\n",
    "        result[:,:,4]=lap\n",
    "        \n",
    "        image= result;\n",
    "        \n",
    "        mask=cv2.resize(mask,self.image_size);\n",
    "        mask = np.expand_dims(mask,axis=-1);\n",
    "        mask =np.maximum(mask,mask);\n",
    "        \n",
    "        \n",
    "        \n",
    "        image =image/255.0;\n",
    "        \n",
    "        mask = mask/255.0;\n",
    "        \n",
    "        \n",
    "        return image, mask;\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        if (index+1)*self.batch_size >len(self.ids):\n",
    "            self.bach_size=len(self.ids)-index*batch_size;\n",
    "            \n",
    "        files_batch = self.ids[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        image=[];\n",
    "        mask=[];\n",
    "        \n",
    "        for id_name in files_batch:\n",
    "            _img,_mask = self.__load__(id_name)\n",
    "            image.append(_img)\n",
    "            mask.append(_mask);\n",
    "        \n",
    "        image =np.array(image)\n",
    "        mask =np.array(mask);\n",
    "        \n",
    "        return image, mask;\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        pass;\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.ids)/float(self.batch_size)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256,256);\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_block(x,filters,kernel_size=(3,3),padding=\"same\",strides=1):\n",
    "    c = keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=\"relu\")(x);\n",
    "    c = keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=\"relu\")(c);\n",
    "    p = keras.layers.MaxPool2D((2,2),(2,2))(c);\n",
    "    \n",
    "    return c,p\n",
    "\n",
    "def up_block(x,skip,filters,kernel_size=(3,3),padding=\"same\",strides=1):\n",
    "    us=keras.layers.UpSampling2D((2,2))(x);\n",
    "    concat = keras.layers.Concatenate()([us,skip])\n",
    "    c = keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=\"relu\")(concat);\n",
    "    c = keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=\"relu\")(c);\n",
    "    return c;\n",
    "\n",
    "\n",
    "def bottleneck(x,filters,kernel_size=(3,3),padding=\"same\",strides=1):\n",
    "    c = keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=\"relu\")(x);\n",
    "    c = keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=\"relu\")(c);\n",
    "    return c;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet():\n",
    "    f = [16,32,64,128,256,512];\n",
    "    \n",
    "    inputs = keras.layers.Input(image_size+(5,))\n",
    "    \n",
    "    p0=inputs;\n",
    "    c1,p1 = down_block(p0,f[0])  \n",
    "    c2,p2 = down_block(p1,f[1]) \n",
    "    c3,p3 = down_block(p2,f[2])\n",
    "    #c5,p5 = down_block(p4,f[4])\n",
    "    \n",
    "    #bn = bottleneck(p5,f[5])\n",
    "    bn = bottleneck(p3,f[3])\n",
    "    \n",
    "    #u5= up_block(bn,c5,f[4])\n",
    "    #u4= up_block(u5,c4,f[3])\n",
    "    u3= up_block(bn,c3,f[2])\n",
    "    u2= up_block(u3,c2,f[1])\n",
    "    u1= up_block(u2,c1,f[0])\n",
    "    \n",
    "    outputs = keras.layers.Conv2D(1,(1,1),padding=\"same\",activation='sigmoid')(u1);\n",
    "    model = keras.models.Model(inputs,outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth=1\n",
    "def dice_coef(y_true,y_pred):\n",
    "    \n",
    "    y_true_f = keras.layers.Flatten()(y_true)\n",
    "    y_pred_f = keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true_f* y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f)+tf.reduce_sum(y_pred_f)+ smooth )\n",
    "    \n",
    "def dice_coef_loss(y_true,y_pred):\n",
    "    return 1.0- dice_coef(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\",loss=\"binary_crossentropy\",metrics=['acc',f1_m,precision_m, recall_m,dice_coef_loss]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "8/8 [==============================] - 22s 3s/step - loss: 0.6948 - acc: 0.5044 - f1_m: 0.4205 - precision_m: 0.4885 - recall_m: 0.5746 - dice_coef_loss: 0.4920 - val_loss: 0.6930 - val_acc: 0.4989 - val_f1_m: 1.4034e-04 - val_precision_m: 0.3815 - val_recall_m: 7.0181e-05 - val_dice_coef_loss: 0.5206\n",
      "Epoch 2/150\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.6905 - acc: 0.4955 - f1_m: 5.9686e-05 - precision_m: 0.5337 - recall_m: 2.9847e-05 - dice_coef_loss: 0.5232 - val_loss: 0.6937 - val_acc: 0.4990 - val_f1_m: 9.5856e-04 - val_precision_m: 0.6589 - val_recall_m: 4.7966e-04 - val_dice_coef_loss: 0.5206\n",
      "Epoch 3/150\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.6895 - acc: 0.5055 - f1_m: 0.1876 - precision_m: 0.7242 - recall_m: 0.1347 - dice_coef_loss: 0.5030 - val_loss: 0.6940 - val_acc: 0.4938 - val_f1_m: 0.3179 - val_precision_m: 0.4773 - val_recall_m: 0.2412 - val_dice_coef_loss: 0.5110\n",
      "Epoch 4/150\n",
      "8/8 [==============================] - 22s 3s/step - loss: 0.6799 - acc: 0.5615 - f1_m: 0.1658 - precision_m: 0.8178 - recall_m: 0.1209 - dice_coef_loss: 0.5382 - val_loss: 0.7100 - val_acc: 0.5082 - val_f1_m: 0.0392 - val_precision_m: 0.9169 - val_recall_m: 0.0201 - val_dice_coef_loss: 0.5543\n",
      "Epoch 5/150\n",
      "8/8 [==============================] - 31s 4s/step - loss: 0.6891 - acc: 0.5296 - f1_m: 0.4298 - precision_m: 0.6743 - recall_m: 0.4861 - dice_coef_loss: 0.5040 - val_loss: 0.6954 - val_acc: 0.4820 - val_f1_m: 0.5917 - val_precision_m: 0.4818 - val_recall_m: 0.7706 - val_dice_coef_loss: 0.4961\n",
      "Epoch 6/150\n",
      "8/8 [==============================] - 30s 4s/step - loss: 0.6804 - acc: 0.5982 - f1_m: 0.6133 - precision_m: 0.6151 - recall_m: 0.6340 - dice_coef_loss: 0.4852 - val_loss: 0.6985 - val_acc: 0.5127 - val_f1_m: 0.5444 - val_precision_m: 0.5047 - val_recall_m: 0.5965 - val_dice_coef_loss: 0.4975\n",
      "Epoch 7/150\n",
      "8/8 [==============================] - 30s 4s/step - loss: 0.6613 - acc: 0.6033 - f1_m: 0.5734 - precision_m: 0.6261 - recall_m: 0.5629 - dice_coef_loss: 0.4902 - val_loss: 0.7378 - val_acc: 0.5083 - val_f1_m: 0.3470 - val_precision_m: 0.5074 - val_recall_m: 0.2667 - val_dice_coef_loss: 0.5475\n",
      "Epoch 8/150\n",
      "8/8 [==============================] - 38s 5s/step - loss: 0.6691 - acc: 0.6055 - f1_m: 0.5464 - precision_m: 0.7124 - recall_m: 0.4865 - dice_coef_loss: 0.4749 - val_loss: 0.7030 - val_acc: 0.5166 - val_f1_m: 0.3455 - val_precision_m: 0.5256 - val_recall_m: 0.2596 - val_dice_coef_loss: 0.5316\n",
      "Epoch 9/150\n",
      "8/8 [==============================] - 39s 5s/step - loss: 0.6669 - acc: 0.5868 - f1_m: 0.5766 - precision_m: 0.6154 - recall_m: 0.6016 - dice_coef_loss: 0.4772 - val_loss: 0.6989 - val_acc: 0.5175 - val_f1_m: 0.5671 - val_precision_m: 0.5082 - val_recall_m: 0.6457 - val_dice_coef_loss: 0.4813\n",
      "Epoch 10/150\n",
      "8/8 [==============================] - 48s 6s/step - loss: 0.6587 - acc: 0.6021 - f1_m: 0.5435 - precision_m: 0.6753 - recall_m: 0.4879 - dice_coef_loss: 0.4851 - val_loss: 0.6983 - val_acc: 0.5234 - val_f1_m: 0.3752 - val_precision_m: 0.5356 - val_recall_m: 0.2913 - val_dice_coef_loss: 0.5247\n",
      "Epoch 11/150\n",
      "8/8 [==============================] - 53s 7s/step - loss: 0.6482 - acc: 0.6129 - f1_m: 0.5801 - precision_m: 0.6552 - recall_m: 0.5499 - dice_coef_loss: 0.4677 - val_loss: 0.7126 - val_acc: 0.5264 - val_f1_m: 0.5587 - val_precision_m: 0.5176 - val_recall_m: 0.6116 - val_dice_coef_loss: 0.4735\n",
      "Epoch 12/150\n",
      "8/8 [==============================] - 52s 7s/step - loss: 0.6341 - acc: 0.6376 - f1_m: 0.5622 - precision_m: 0.6784 - recall_m: 0.5011 - dice_coef_loss: 0.4776 - val_loss: 0.7477 - val_acc: 0.5335 - val_f1_m: 0.5001 - val_precision_m: 0.5331 - val_recall_m: 0.4765 - val_dice_coef_loss: 0.4856\n",
      "Epoch 13/150\n",
      "8/8 [==============================] - 52s 7s/step - loss: 0.6543 - acc: 0.5967 - f1_m: 0.5608 - precision_m: 0.6951 - recall_m: 0.4983 - dice_coef_loss: 0.4464 - val_loss: 0.7001 - val_acc: 0.5293 - val_f1_m: 0.5803 - val_precision_m: 0.5182 - val_recall_m: 0.6629 - val_dice_coef_loss: 0.4629\n",
      "Epoch 14/150\n",
      "8/8 [==============================] - 53s 7s/step - loss: 0.6434 - acc: 0.6109 - f1_m: 0.5791 - precision_m: 0.6486 - recall_m: 0.5546 - dice_coef_loss: 0.4634 - val_loss: 0.6934 - val_acc: 0.5482 - val_f1_m: 0.4877 - val_precision_m: 0.5557 - val_recall_m: 0.4386 - val_dice_coef_loss: 0.4875\n",
      "Epoch 15/150\n",
      "8/8 [==============================] - 55s 7s/step - loss: 0.6206 - acc: 0.6386 - f1_m: 0.6053 - precision_m: 0.6898 - recall_m: 0.5542 - dice_coef_loss: 0.4264 - val_loss: 0.6940 - val_acc: 0.5583 - val_f1_m: 0.4759 - val_precision_m: 0.5767 - val_recall_m: 0.4089 - val_dice_coef_loss: 0.4872\n",
      "Epoch 16/150\n",
      "8/8 [==============================] - 52s 7s/step - loss: 0.6292 - acc: 0.6304 - f1_m: 0.5613 - precision_m: 0.7062 - recall_m: 0.4848 - dice_coef_loss: 0.4515 - val_loss: 0.6725 - val_acc: 0.5680 - val_f1_m: 0.4572 - val_precision_m: 0.6052 - val_recall_m: 0.3706 - val_dice_coef_loss: 0.4902\n",
      "Epoch 17/150\n",
      "8/8 [==============================] - 52s 7s/step - loss: 0.6201 - acc: 0.6364 - f1_m: 0.5731 - precision_m: 0.7335 - recall_m: 0.5204 - dice_coef_loss: 0.4358 - val_loss: 0.6847 - val_acc: 0.5582 - val_f1_m: 0.2996 - val_precision_m: 0.7138 - val_recall_m: 0.1917 - val_dice_coef_loss: 0.5321\n",
      "Epoch 18/150\n",
      "8/8 [==============================] - 51s 6s/step - loss: 0.6082 - acc: 0.6491 - f1_m: 0.5907 - precision_m: 0.7272 - recall_m: 0.5204 - dice_coef_loss: 0.4342 - val_loss: 0.6631 - val_acc: 0.5782 - val_f1_m: 0.4535 - val_precision_m: 0.6335 - val_recall_m: 0.3571 - val_dice_coef_loss: 0.4849\n",
      "Epoch 19/150\n",
      "8/8 [==============================] - 52s 6s/step - loss: 0.5932 - acc: 0.6678 - f1_m: 0.6104 - precision_m: 0.7412 - recall_m: 0.5306 - dice_coef_loss: 0.4154 - val_loss: 0.6573 - val_acc: 0.6011 - val_f1_m: 0.4469 - val_precision_m: 0.7173 - val_recall_m: 0.3290 - val_dice_coef_loss: 0.4817\n",
      "Epoch 20/150\n",
      "8/8 [==============================] - 52s 7s/step - loss: 0.6073 - acc: 0.6383 - f1_m: 0.5603 - precision_m: 0.8005 - recall_m: 0.4618 - dice_coef_loss: 0.4248 - val_loss: 0.6581 - val_acc: 0.5897 - val_f1_m: 0.3790 - val_precision_m: 0.7697 - val_recall_m: 0.2549 - val_dice_coef_loss: 0.5027\n",
      "Epoch 21/150\n",
      "8/8 [==============================] - 52s 7s/step - loss: 0.5945 - acc: 0.6600 - f1_m: 0.6172 - precision_m: 0.7519 - recall_m: 0.5611 - dice_coef_loss: 0.4086 - val_loss: 0.6503 - val_acc: 0.6029 - val_f1_m: 0.4697 - val_precision_m: 0.6964 - val_recall_m: 0.3586 - val_dice_coef_loss: 0.4685\n",
      "Epoch 22/150\n",
      "8/8 [==============================] - 54s 7s/step - loss: 0.5917 - acc: 0.6730 - f1_m: 0.5948 - precision_m: 0.7857 - recall_m: 0.4935 - dice_coef_loss: 0.4171 - val_loss: 0.6454 - val_acc: 0.6081 - val_f1_m: 0.4903 - val_precision_m: 0.6913 - val_recall_m: 0.3841 - val_dice_coef_loss: 0.4623\n",
      "Epoch 23/150\n",
      "8/8 [==============================] - 58s 7s/step - loss: 0.5785 - acc: 0.6754 - f1_m: 0.6105 - precision_m: 0.7956 - recall_m: 0.5154 - dice_coef_loss: 0.4053 - val_loss: 0.6361 - val_acc: 0.6257 - val_f1_m: 0.5673 - val_precision_m: 0.6661 - val_recall_m: 0.4978 - val_dice_coef_loss: 0.4236\n",
      "Epoch 24/150\n",
      "8/8 [==============================] - 75s 9s/step - loss: 0.5819 - acc: 0.6785 - f1_m: 0.6224 - precision_m: 0.7746 - recall_m: 0.5368 - dice_coef_loss: 0.4019 - val_loss: 0.6571 - val_acc: 0.6040 - val_f1_m: 0.5738 - val_precision_m: 0.6150 - val_recall_m: 0.5437 - val_dice_coef_loss: 0.4210\n",
      "Epoch 25/150\n",
      "8/8 [==============================] - 82s 10s/step - loss: 0.5878 - acc: 0.6772 - f1_m: 0.6227 - precision_m: 0.7644 - recall_m: 0.5688 - dice_coef_loss: 0.4075 - val_loss: 0.6081 - val_acc: 0.6460 - val_f1_m: 0.5767 - val_precision_m: 0.7072 - val_recall_m: 0.4933 - val_dice_coef_loss: 0.4342\n",
      "Epoch 26/150\n",
      "8/8 [==============================] - 82s 10s/step - loss: 0.5579 - acc: 0.7017 - f1_m: 0.6584 - precision_m: 0.7974 - recall_m: 0.5745 - dice_coef_loss: 0.3914 - val_loss: 0.6000 - val_acc: 0.6498 - val_f1_m: 0.5702 - val_precision_m: 0.7281 - val_recall_m: 0.4744 - val_dice_coef_loss: 0.4285\n",
      "Epoch 27/150\n",
      "8/8 [==============================] - 84s 10s/step - loss: 0.5520 - acc: 0.7036 - f1_m: 0.6849 - precision_m: 0.7645 - recall_m: 0.6544 - dice_coef_loss: 0.3714 - val_loss: 0.6339 - val_acc: 0.6356 - val_f1_m: 0.5348 - val_precision_m: 0.7292 - val_recall_m: 0.4284 - val_dice_coef_loss: 0.4533\n",
      "Epoch 28/150\n",
      "8/8 [==============================] - 87s 11s/step - loss: 0.5552 - acc: 0.6953 - f1_m: 0.6442 - precision_m: 0.7900 - recall_m: 0.5702 - dice_coef_loss: 0.3895 - val_loss: 0.6088 - val_acc: 0.6558 - val_f1_m: 0.5962 - val_precision_m: 0.7073 - val_recall_m: 0.5253 - val_dice_coef_loss: 0.4476\n",
      "Epoch 29/150\n",
      "8/8 [==============================] - 87s 11s/step - loss: 0.5763 - acc: 0.6993 - f1_m: 0.6607 - precision_m: 0.7786 - recall_m: 0.6008 - dice_coef_loss: 0.3931 - val_loss: 0.6345 - val_acc: 0.6342 - val_f1_m: 0.4893 - val_precision_m: 0.7950 - val_recall_m: 0.3583 - val_dice_coef_loss: 0.4818\n",
      "Epoch 30/150\n",
      "8/8 [==============================] - 91s 11s/step - loss: 0.5629 - acc: 0.6979 - f1_m: 0.6877 - precision_m: 0.7481 - recall_m: 0.6854 - dice_coef_loss: 0.3837 - val_loss: 0.6041 - val_acc: 0.6473 - val_f1_m: 0.5350 - val_precision_m: 0.7671 - val_recall_m: 0.4170 - val_dice_coef_loss: 0.4611\n",
      "Epoch 31/150\n",
      "8/8 [==============================] - 84s 10s/step - loss: 0.5476 - acc: 0.7036 - f1_m: 0.6355 - precision_m: 0.8024 - recall_m: 0.5612 - dice_coef_loss: 0.4135 - val_loss: 0.7270 - val_acc: 0.6008 - val_f1_m: 0.6867 - val_precision_m: 0.5638 - val_recall_m: 0.8825 - val_dice_coef_loss: 0.3699\n",
      "Epoch 32/150\n",
      "8/8 [==============================] - 89s 11s/step - loss: 0.5296 - acc: 0.7252 - f1_m: 0.7202 - precision_m: 0.7552 - recall_m: 0.7177 - dice_coef_loss: 0.3586 - val_loss: 0.6075 - val_acc: 0.6906 - val_f1_m: 0.7296 - val_precision_m: 0.6462 - val_recall_m: 0.8389 - val_dice_coef_loss: 0.3659\n",
      "Epoch 33/150\n",
      "8/8 [==============================] - 94s 12s/step - loss: 0.5286 - acc: 0.7380 - f1_m: 0.7457 - precision_m: 0.7434 - recall_m: 0.7572 - dice_coef_loss: 0.3487 - val_loss: 0.5495 - val_acc: 0.7168 - val_f1_m: 0.7395 - val_precision_m: 0.6818 - val_recall_m: 0.8106 - val_dice_coef_loss: 0.3740\n",
      "Epoch 34/150\n",
      "8/8 [==============================] - 88s 11s/step - loss: 0.5004 - acc: 0.7466 - f1_m: 0.7418 - precision_m: 0.7484 - recall_m: 0.7567 - dice_coef_loss: 0.3493 - val_loss: 0.5612 - val_acc: 0.7242 - val_f1_m: 0.7558 - val_precision_m: 0.6789 - val_recall_m: 0.8547 - val_dice_coef_loss: 0.3396\n",
      "Epoch 35/150\n",
      "8/8 [==============================] - 90s 11s/step - loss: 0.4608 - acc: 0.7795 - f1_m: 0.7882 - precision_m: 0.7840 - recall_m: 0.7971 - dice_coef_loss: 0.2970 - val_loss: 0.4652 - val_acc: 0.7837 - val_f1_m: 0.7938 - val_precision_m: 0.7600 - val_recall_m: 0.8312 - val_dice_coef_loss: 0.2903\n",
      "Epoch 36/150\n",
      "8/8 [==============================] - 89s 11s/step - loss: 0.4954 - acc: 0.7627 - f1_m: 0.7699 - precision_m: 0.7698 - recall_m: 0.7908 - dice_coef_loss: 0.3161 - val_loss: 0.5130 - val_acc: 0.7440 - val_f1_m: 0.7531 - val_precision_m: 0.7244 - val_recall_m: 0.7884 - val_dice_coef_loss: 0.3506\n",
      "Epoch 37/150\n",
      "8/8 [==============================] - 95s 12s/step - loss: 0.4751 - acc: 0.7726 - f1_m: 0.7860 - precision_m: 0.7626 - recall_m: 0.8238 - dice_coef_loss: 0.3070 - val_loss: 0.5161 - val_acc: 0.7474 - val_f1_m: 0.7025 - val_precision_m: 0.8467 - val_recall_m: 0.6054 - val_dice_coef_loss: 0.3767\n",
      "Epoch 38/150\n",
      "8/8 [==============================] - 84s 10s/step - loss: 0.4488 - acc: 0.7894 - f1_m: 0.7841 - precision_m: 0.8121 - recall_m: 0.7654 - dice_coef_loss: 0.3059 - val_loss: 0.6056 - val_acc: 0.6974 - val_f1_m: 0.7531 - val_precision_m: 0.6371 - val_recall_m: 0.9215 - val_dice_coef_loss: 0.2895\n",
      "Epoch 39/150\n",
      "8/8 [==============================] - 89s 11s/step - loss: 0.4763 - acc: 0.7678 - f1_m: 0.7698 - precision_m: 0.7906 - recall_m: 0.7723 - dice_coef_loss: 0.3095 - val_loss: 0.4720 - val_acc: 0.7731 - val_f1_m: 0.7914 - val_precision_m: 0.7319 - val_recall_m: 0.8617 - val_dice_coef_loss: 0.3024\n",
      "Epoch 40/150\n",
      "8/8 [==============================] - 95s 12s/step - loss: 0.4790 - acc: 0.7669 - f1_m: 0.7863 - precision_m: 0.7680 - recall_m: 0.8270 - dice_coef_loss: 0.2977 - val_loss: 0.4702 - val_acc: 0.7843 - val_f1_m: 0.7839 - val_precision_m: 0.7854 - val_recall_m: 0.7832 - val_dice_coef_loss: 0.3300\n",
      "Epoch 41/150\n",
      "8/8 [==============================] - 89s 11s/step - loss: 0.4709 - acc: 0.7667 - f1_m: 0.7723 - precision_m: 0.7775 - recall_m: 0.7849 - dice_coef_loss: 0.3094 - val_loss: 0.4579 - val_acc: 0.7752 - val_f1_m: 0.7962 - val_precision_m: 0.7295 - val_recall_m: 0.8767 - val_dice_coef_loss: 0.2856\n",
      "Epoch 42/150\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_data = DataGen(train_ids,batch_size=batch_size,image_size = image_size)\n",
    "valid_data = DataGen(test_ids,batch_size=batch_size,image_size = image_size)\n",
    "    \n",
    "train_steps= len(train_ids)//batch_size;\n",
    "valid_steps= len(test_ids)//batch_size;\n",
    "    \n",
    "epochs = 150;\n",
    "#model.load_weights(\"model_test_check.hdf5\")\n",
    "result = model.fit_generator(train_data, validation_data=valid_data, \n",
    "                                 steps_per_epoch=train_steps, \n",
    "                                 validation_steps=valid_steps, \n",
    "                                 epochs=epochs,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = str(result.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"unet_5c.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"unet_5c_history.json\",\"w\") as f:\n",
    "    json.dump(history,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
