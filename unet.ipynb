{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;\n",
    "import sys;\n",
    "import random;\n",
    "import json\n",
    "\n",
    "import numpy as np;\n",
    "import cv2;\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras;\n",
    "import openslide\n",
    "import imutils\n",
    "\n",
    "import pylab\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from skimage.data import astronaut\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import sobel;\n",
    "import skimage\n",
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "\n",
    "\n",
    "import skimage.filters as filters\n",
    "import skimage.draw as draw\n",
    "import skimage.color as color\n",
    "\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "60\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "datapath=\"./gland/\";\n",
    "\n",
    "train_ids=[];\n",
    "test_ids=[];\n",
    "test_ids2=[];\n",
    "\n",
    "files=os.listdir(datapath)\n",
    "for i in files:\n",
    "    i = i.replace(\"_anno.bmp\",\"\").replace(\".bmp\",\"\");\n",
    "    if i.startswith(\"testB\"):\n",
    "        test_ids2.append(i)\n",
    "        \n",
    "    elif i.startswith(\"train\"):\n",
    "        train_ids.append(i)\n",
    "        \n",
    "    elif i.startswith(\"testA\"):\n",
    "        test_ids.append(i)\n",
    "        \n",
    "\n",
    "train_ids=list(set(train_ids))\n",
    "test_ids=list(set(test_ids))\n",
    "test_ids2=list(set(test_ids2))\n",
    "\n",
    "\n",
    "print(len(train_ids))\n",
    "print(len(test_ids))\n",
    "print(len(test_ids2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen(keras.utils.Sequence):\n",
    "    def __init__(self,ids,batch_size=0,image_size=(256,256)):\n",
    "        self.ids=ids;\n",
    "        \n",
    "        self.batch_size =batch_size;\n",
    "        self.image_size = image_size;\n",
    "        \n",
    "        \n",
    "    def __load__(self,id_name):\n",
    "        \n",
    "        path=datapath;\n",
    "        \n",
    "        image_path = os.path.join(path,id_name)+\".bmp\";\n",
    "        \n",
    "        image = cv2.imread(image_path);\n",
    "        \n",
    "        mask_path= os.path.join(path,id_name)+\"_anno.bmp\";\n",
    "        mask = cv2.imread(mask_path,-1);\n",
    "        \n",
    "        thresh =0.5\n",
    "        mask = cv2.threshold(mask, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "        \n",
    "        image =  cv2.normalize(image, None, 0, 255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC3)\n",
    "        \n",
    "        \n",
    "        image = cv2.resize(image,self.image_size);\n",
    "        \n",
    "        mask=cv2.resize(mask,self.image_size);\n",
    "        mask = np.expand_dims(mask,axis=-1);\n",
    "        mask =np.maximum(mask,mask);\n",
    "        \n",
    "        image =image/255.0;\n",
    "        \n",
    "        mask = mask/255.0;\n",
    "        \n",
    "        \n",
    "        return image, mask;\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        if (index+1)*self.batch_size >len(self.ids):\n",
    "            self.bach_size=len(self.ids)-index*batch_size;\n",
    "            \n",
    "        files_batch = self.ids[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        image=[];\n",
    "        mask=[];\n",
    "        \n",
    "        for id_name in files_batch:\n",
    "            _img,_mask = self.__load__(id_name)\n",
    "            image.append(_img)\n",
    "            mask.append(_mask);\n",
    "        \n",
    "        image =np.array(image)\n",
    "        mask =np.array(mask);\n",
    "        \n",
    "        return image, mask;\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        pass;\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.ids)/float(self.batch_size)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_block(x,filters,kernel_size=(3,3),padding=\"same\",strides=1):\n",
    "    c = keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=\"relu\")(x);\n",
    "    c = keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=\"relu\")(c);\n",
    "    p = keras.layers.MaxPool2D((2,2),(2,2))(c);\n",
    "    \n",
    "    return c,p\n",
    "\n",
    "def up_block(x,skip,filters,kernel_size=(3,3),padding=\"same\",strides=1):\n",
    "    us=keras.layers.UpSampling2D((2,2))(x);\n",
    "    concat = keras.layers.Concatenate()([us,skip])\n",
    "    c = keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=\"relu\")(concat);\n",
    "    c = keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=\"relu\")(c);\n",
    "    return c;\n",
    "\n",
    "\n",
    "def bottleneck(x,filters,kernel_size=(3,3),padding=\"same\",strides=1):\n",
    "    c = keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=\"relu\")(x);\n",
    "    c = keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=\"relu\")(c);\n",
    "    return c;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet():\n",
    "    f = [16,32,64,128,256,512];\n",
    "    \n",
    "    inputs = keras.layers.Input(image_size+(3,))\n",
    "    \n",
    "    p0=inputs;\n",
    "    c1,p1 = down_block(p0,f[0])  \n",
    "    c2,p2 = down_block(p1,f[1]) \n",
    "    c3,p3 = down_block(p2,f[2])\n",
    "    #c5,p5 = down_block(p4,f[4])\n",
    "    \n",
    "    #bn = bottleneck(p5,f[5])\n",
    "    bn = bottleneck(p3,f[3])\n",
    "    \n",
    "    #u5= up_block(bn,c5,f[4])\n",
    "    #u4= up_block(u5,c4,f[3])\n",
    "    u3= up_block(bn,c3,f[2])\n",
    "    u2= up_block(u3,c2,f[1])\n",
    "    u1= up_block(u2,c1,f[0])\n",
    "    \n",
    "    outputs = keras.layers.Conv2D(1,(1,1),padding=\"same\",activation='sigmoid')(u1);\n",
    "    model = keras.models.Model(inputs,outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256,256);\n",
    "batch_size = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth=1\n",
    "def dice_coef(y_true,y_pred):\n",
    "    \n",
    "    y_true_f = keras.layers.Flatten()(y_true)\n",
    "    y_pred_f = keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true_f* y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f)+tf.reduce_sum(y_pred_f)+ smooth )\n",
    "    \n",
    "def dice_coef_loss(y_true,y_pred):\n",
    "    return 1.0- dice_coef(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 256, 256, 16) 448         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 256, 256, 16) 2320        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 128, 128, 16) 0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 128, 128, 32) 4640        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 64, 64, 32)   0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 64, 64, 64)   18496       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 32, 32, 128)  73856       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 64, 64, 128)  0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 64, 64, 192)  0           up_sampling2d_9[0][0]            \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 64, 64, 64)   110656      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 128, 128, 64) 0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 128, 128, 96) 0           up_sampling2d_10[0][0]           \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 128, 128, 32) 27680       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 256, 256, 32) 0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 256, 256, 48) 0           up_sampling2d_11[0][0]           \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 256, 256, 16) 6928        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 256, 256, 16) 2320        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 256, 256, 1)  17          conv2d_58[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 487,297\n",
      "Trainable params: 487,297\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\",loss=\"binary_crossentropy\",metrics=['acc',f1_m,precision_m, recall_m,dice_coef_loss]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "8/8 [==============================] - 20s 2s/step - loss: 0.6948 - acc: 0.4938 - f1_m: 0.4230 - precision_m: 0.5499 - recall_m: 0.4816 - dice_coef_loss: 0.4965 - val_loss: 0.6936 - val_acc: 0.5109 - val_f1_m: 0.3065 - val_precision_m: 0.5254 - val_recall_m: 0.2206 - val_dice_coef_loss: 0.5097\n",
      "Epoch 2/150\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.6876 - acc: 0.5227 - f1_m: 0.0750 - precision_m: 0.6249 - recall_m: 0.0456 - dice_coef_loss: 0.5312 - val_loss: 0.6966 - val_acc: 0.5149 - val_f1_m: 0.3995 - val_precision_m: 0.5227 - val_recall_m: 0.3296 - val_dice_coef_loss: 0.5155\n",
      "Epoch 3/150\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.6922 - acc: 0.5412 - f1_m: 0.5152 - precision_m: 0.6390 - recall_m: 0.6080 - dice_coef_loss: 0.4908 - val_loss: 0.7076 - val_acc: 0.5227 - val_f1_m: 0.1104 - val_precision_m: 0.8350 - val_recall_m: 0.0602 - val_dice_coef_loss: 0.5448\n",
      "Epoch 4/150\n",
      "8/8 [==============================] - 18s 2s/step - loss: 0.6784 - acc: 0.5854 - f1_m: 0.3907 - precision_m: 0.7560 - recall_m: 0.3343 - dice_coef_loss: 0.5201 - val_loss: 0.7028 - val_acc: 0.4904 - val_f1_m: 0.4301 - val_precision_m: 0.4841 - val_recall_m: 0.3940 - val_dice_coef_loss: 0.5179\n",
      "Epoch 5/150\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.6780 - acc: 0.5874 - f1_m: 0.5212 - precision_m: 0.6519 - recall_m: 0.4497 - dice_coef_loss: 0.4996 - val_loss: 0.7062 - val_acc: 0.4881 - val_f1_m: 0.4635 - val_precision_m: 0.4825 - val_recall_m: 0.4525 - val_dice_coef_loss: 0.5139\n",
      "Epoch 6/150\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.6690 - acc: 0.6044 - f1_m: 0.5886 - precision_m: 0.6038 - recall_m: 0.5888 - dice_coef_loss: 0.4880 - val_loss: 0.7123 - val_acc: 0.4875 - val_f1_m: 0.3948 - val_precision_m: 0.4796 - val_recall_m: 0.3439 - val_dice_coef_loss: 0.5191\n",
      "Epoch 7/150\n",
      "8/8 [==============================] - 20s 2s/step - loss: 0.6517 - acc: 0.6082 - f1_m: 0.5329 - precision_m: 0.6612 - recall_m: 0.4627 - dice_coef_loss: 0.4767 - val_loss: 0.8251 - val_acc: 0.4884 - val_f1_m: 0.4854 - val_precision_m: 0.4864 - val_recall_m: 0.4945 - val_dice_coef_loss: 0.4723\n",
      "Epoch 8/150\n",
      "8/8 [==============================] - 18s 2s/step - loss: 0.6805 - acc: 0.5701 - f1_m: 0.3589 - precision_m: 0.8385 - recall_m: 0.2702 - dice_coef_loss: 0.4927 - val_loss: 0.6943 - val_acc: 0.5360 - val_f1_m: 0.2270 - val_precision_m: 0.6825 - val_recall_m: 0.1408 - val_dice_coef_loss: 0.5241\n",
      "Epoch 9/150\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.6639 - acc: 0.5953 - f1_m: 0.4776 - precision_m: 0.6995 - recall_m: 0.4150 - dice_coef_loss: 0.4828 - val_loss: 0.7704 - val_acc: 0.4674 - val_f1_m: 0.5724 - val_precision_m: 0.4743 - val_recall_m: 0.7241 - val_dice_coef_loss: 0.4510\n",
      "Epoch 10/150\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.6559 - acc: 0.5977 - f1_m: 0.5353 - precision_m: 0.6680 - recall_m: 0.4862 - dice_coef_loss: 0.4706 - val_loss: 0.7100 - val_acc: 0.4989 - val_f1_m: 0.3258 - val_precision_m: 0.5049 - val_recall_m: 0.2498 - val_dice_coef_loss: 0.5111\n",
      "Epoch 11/150\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.6486 - acc: 0.6038 - f1_m: 0.5071 - precision_m: 0.6901 - recall_m: 0.4153 - dice_coef_loss: 0.4596 - val_loss: 0.7134 - val_acc: 0.5002 - val_f1_m: 0.3489 - val_precision_m: 0.5050 - val_recall_m: 0.2758 - val_dice_coef_loss: 0.4979\n",
      "Epoch 12/150\n",
      "8/8 [==============================] - 18s 2s/step - loss: 0.6404 - acc: 0.5950 - f1_m: 0.4857 - precision_m: 0.6927 - recall_m: 0.3924 - dice_coef_loss: 0.4606 - val_loss: 0.7051 - val_acc: 0.5139 - val_f1_m: 0.3249 - val_precision_m: 0.5402 - val_recall_m: 0.2418 - val_dice_coef_loss: 0.4977\n",
      "Epoch 13/150\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.6571 - acc: 0.6091 - f1_m: 0.5043 - precision_m: 0.7774 - recall_m: 0.4164 - dice_coef_loss: 0.4398 - val_loss: 0.7027 - val_acc: 0.5318 - val_f1_m: 0.1438 - val_precision_m: 0.8651 - val_recall_m: 0.0805 - val_dice_coef_loss: 0.5420\n",
      "Epoch 14/150\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.6896 - acc: 0.5013 - f1_m: 0.0684 - precision_m: 0.9212 - recall_m: 0.0365 - dice_coef_loss: 0.5259 - val_loss: 0.6944 - val_acc: 0.5319 - val_f1_m: 0.1915 - val_precision_m: 0.7054 - val_recall_m: 0.1135 - val_dice_coef_loss: 0.5203\n",
      "Epoch 15/150\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.6821 - acc: 0.5802 - f1_m: 0.3376 - precision_m: 0.8310 - recall_m: 0.2174 - dice_coef_loss: 0.5120 - val_loss: 0.6932 - val_acc: 0.5357 - val_f1_m: 0.2796 - val_precision_m: 0.6241 - val_recall_m: 0.1841 - val_dice_coef_loss: 0.5157\n",
      "Epoch 16/150\n",
      "8/8 [==============================] - 25s 3s/step - loss: 0.6837 - acc: 0.5765 - f1_m: 0.3372 - precision_m: 0.7951 - recall_m: 0.2190 - dice_coef_loss: 0.5123 - val_loss: 0.6944 - val_acc: 0.5395 - val_f1_m: 0.2602 - val_precision_m: 0.6634 - val_recall_m: 0.1654 - val_dice_coef_loss: 0.5222\n",
      "Epoch 17/150\n",
      "8/8 [==============================] - 23s 3s/step - loss: 0.6799 - acc: 0.5974 - f1_m: 0.3992 - precision_m: 0.7637 - recall_m: 0.2772 - dice_coef_loss: 0.5174 - val_loss: 0.6941 - val_acc: 0.5412 - val_f1_m: 0.2740 - val_precision_m: 0.6549 - val_recall_m: 0.1773 - val_dice_coef_loss: 0.5240\n",
      "Epoch 18/150\n",
      "8/8 [==============================] - 24s 3s/step - loss: 0.6774 - acc: 0.5850 - f1_m: 0.4904 - precision_m: 0.6923 - recall_m: 0.4249 - dice_coef_loss: 0.4857 - val_loss: 0.6955 - val_acc: 0.5413 - val_f1_m: 0.2862 - val_precision_m: 0.6434 - val_recall_m: 0.1890 - val_dice_coef_loss: 0.5270\n",
      "Epoch 19/150\n",
      "8/8 [==============================] - 24s 3s/step - loss: 0.6659 - acc: 0.6022 - f1_m: 0.4889 - precision_m: 0.7114 - recall_m: 0.4116 - dice_coef_loss: 0.4903 - val_loss: 0.6835 - val_acc: 0.5390 - val_f1_m: 0.3724 - val_precision_m: 0.5830 - val_recall_m: 0.2806 - val_dice_coef_loss: 0.4976\n",
      "Epoch 20/150\n",
      "8/8 [==============================] - 28s 4s/step - loss: 0.6464 - acc: 0.6205 - f1_m: 0.5053 - precision_m: 0.7352 - recall_m: 0.4148 - dice_coef_loss: 0.4671 - val_loss: 0.7059 - val_acc: 0.5305 - val_f1_m: 0.3772 - val_precision_m: 0.5640 - val_recall_m: 0.2921 - val_dice_coef_loss: 0.4936\n",
      "Epoch 21/150\n",
      "8/8 [==============================] - 28s 3s/step - loss: 0.6387 - acc: 0.6155 - f1_m: 0.5466 - precision_m: 0.7270 - recall_m: 0.4547 - dice_coef_loss: 0.4424 - val_loss: 0.6853 - val_acc: 0.5489 - val_f1_m: 0.2980 - val_precision_m: 0.6778 - val_recall_m: 0.1979 - val_dice_coef_loss: 0.5108\n",
      "Epoch 22/150\n",
      "8/8 [==============================] - 30s 4s/step - loss: 0.6437 - acc: 0.6149 - f1_m: 0.4555 - precision_m: 0.8043 - recall_m: 0.3532 - dice_coef_loss: 0.4637 - val_loss: 0.6873 - val_acc: 0.5469 - val_f1_m: 0.2290 - val_precision_m: 0.7735 - val_recall_m: 0.1387 - val_dice_coef_loss: 0.5211\n",
      "Epoch 23/150\n",
      "8/8 [==============================] - 33s 4s/step - loss: 0.6474 - acc: 0.5945 - f1_m: 0.4777 - precision_m: 0.7798 - recall_m: 0.3923 - dice_coef_loss: 0.4512 - val_loss: 0.6886 - val_acc: 0.5575 - val_f1_m: 0.5005 - val_precision_m: 0.5742 - val_recall_m: 0.4492 - val_dice_coef_loss: 0.4605\n",
      "Epoch 24/150\n",
      "8/8 [==============================] - 36s 5s/step - loss: 0.6341 - acc: 0.6225 - f1_m: 0.5537 - precision_m: 0.7397 - recall_m: 0.4692 - dice_coef_loss: 0.4471 - val_loss: 0.6848 - val_acc: 0.5505 - val_f1_m: 0.3633 - val_precision_m: 0.6285 - val_recall_m: 0.2629 - val_dice_coef_loss: 0.4874\n",
      "Epoch 25/150\n",
      "8/8 [==============================] - 36s 4s/step - loss: 0.6606 - acc: 0.6006 - f1_m: 0.4857 - precision_m: 0.7845 - recall_m: 0.3948 - dice_coef_loss: 0.4493 - val_loss: 0.6943 - val_acc: 0.5460 - val_f1_m: 0.2161 - val_precision_m: 0.8086 - val_recall_m: 0.1290 - val_dice_coef_loss: 0.5341\n",
      "Epoch 26/150\n",
      "8/8 [==============================] - 34s 4s/step - loss: 0.6493 - acc: 0.6332 - f1_m: 0.4443 - precision_m: 0.8467 - recall_m: 0.3183 - dice_coef_loss: 0.4975 - val_loss: 0.7873 - val_acc: 0.4636 - val_f1_m: 0.5815 - val_precision_m: 0.4739 - val_recall_m: 0.7550 - val_dice_coef_loss: 0.4247\n",
      "Epoch 27/150\n",
      "8/8 [==============================] - 34s 4s/step - loss: 0.6423 - acc: 0.6201 - f1_m: 0.5654 - precision_m: 0.6917 - recall_m: 0.5182 - dice_coef_loss: 0.4470 - val_loss: 0.6854 - val_acc: 0.5445 - val_f1_m: 0.4192 - val_precision_m: 0.5797 - val_recall_m: 0.3353 - val_dice_coef_loss: 0.4872\n",
      "Epoch 28/150\n",
      "8/8 [==============================] - 33s 4s/step - loss: 0.6200 - acc: 0.6329 - f1_m: 0.5631 - precision_m: 0.7192 - recall_m: 0.4734 - dice_coef_loss: 0.4344 - val_loss: 0.6867 - val_acc: 0.5591 - val_f1_m: 0.3637 - val_precision_m: 0.6612 - val_recall_m: 0.2575 - val_dice_coef_loss: 0.5015\n",
      "Epoch 29/150\n",
      "8/8 [==============================] - 37s 5s/step - loss: 0.6137 - acc: 0.6409 - f1_m: 0.5643 - precision_m: 0.7811 - recall_m: 0.4608 - dice_coef_loss: 0.4218 - val_loss: 0.6786 - val_acc: 0.5698 - val_f1_m: 0.3393 - val_precision_m: 0.7422 - val_recall_m: 0.2255 - val_dice_coef_loss: 0.5081\n",
      "Epoch 30/150\n",
      "8/8 [==============================] - 33s 4s/step - loss: 0.6129 - acc: 0.6528 - f1_m: 0.5119 - precision_m: 0.7966 - recall_m: 0.4185 - dice_coef_loss: 0.4529 - val_loss: 0.6724 - val_acc: 0.5925 - val_f1_m: 0.5008 - val_precision_m: 0.6472 - val_recall_m: 0.4115 - val_dice_coef_loss: 0.4627\n",
      "Epoch 31/150\n",
      "8/8 [==============================] - 35s 4s/step - loss: 0.5900 - acc: 0.6630 - f1_m: 0.5869 - precision_m: 0.7821 - recall_m: 0.4816 - dice_coef_loss: 0.4162 - val_loss: 0.6570 - val_acc: 0.6172 - val_f1_m: 0.4891 - val_precision_m: 0.7388 - val_recall_m: 0.3671 - val_dice_coef_loss: 0.4772\n",
      "Epoch 32/150\n",
      "8/8 [==============================] - 33s 4s/step - loss: 0.5691 - acc: 0.6856 - f1_m: 0.6546 - precision_m: 0.8101 - recall_m: 0.5623 - dice_coef_loss: 0.3769 - val_loss: 0.6110 - val_acc: 0.6524 - val_f1_m: 0.6091 - val_precision_m: 0.6947 - val_recall_m: 0.5425 - val_dice_coef_loss: 0.4285\n",
      "Epoch 33/150\n",
      "8/8 [==============================] - 39s 5s/step - loss: 0.5526 - acc: 0.7108 - f1_m: 0.6681 - precision_m: 0.7714 - recall_m: 0.5963 - dice_coef_loss: 0.3839 - val_loss: 0.6150 - val_acc: 0.6525 - val_f1_m: 0.6461 - val_precision_m: 0.6572 - val_recall_m: 0.6357 - val_dice_coef_loss: 0.3838\n",
      "Epoch 34/150\n",
      "8/8 [==============================] - 32s 4s/step - loss: 0.5772 - acc: 0.6711 - f1_m: 0.6291 - precision_m: 0.7382 - recall_m: 0.5845 - dice_coef_loss: 0.3865 - val_loss: 0.6119 - val_acc: 0.6512 - val_f1_m: 0.5722 - val_precision_m: 0.7398 - val_recall_m: 0.4670 - val_dice_coef_loss: 0.4499\n",
      "Epoch 35/150\n",
      "8/8 [==============================] - 35s 4s/step - loss: 0.6058 - acc: 0.6723 - f1_m: 0.6133 - precision_m: 0.7827 - recall_m: 0.5379 - dice_coef_loss: 0.4392 - val_loss: 0.6903 - val_acc: 0.5294 - val_f1_m: 0.6104 - val_precision_m: 0.5168 - val_recall_m: 0.7475 - val_dice_coef_loss: 0.4143\n",
      "Epoch 36/150\n",
      "8/8 [==============================] - 35s 4s/step - loss: 0.6029 - acc: 0.6684 - f1_m: 0.6684 - precision_m: 0.6766 - recall_m: 0.6829 - dice_coef_loss: 0.4041 - val_loss: 0.6517 - val_acc: 0.6206 - val_f1_m: 0.5680 - val_precision_m: 0.6573 - val_recall_m: 0.5022 - val_dice_coef_loss: 0.4433\n",
      "Epoch 37/150\n",
      "8/8 [==============================] - 33s 4s/step - loss: 0.5576 - acc: 0.7015 - f1_m: 0.6486 - precision_m: 0.7977 - recall_m: 0.5527 - dice_coef_loss: 0.3854 - val_loss: 0.6240 - val_acc: 0.6545 - val_f1_m: 0.5824 - val_precision_m: 0.7383 - val_recall_m: 0.4821 - val_dice_coef_loss: 0.4219\n",
      "Epoch 38/150\n",
      "8/8 [==============================] - 38s 5s/step - loss: 0.5553 - acc: 0.7013 - f1_m: 0.6350 - precision_m: 0.8109 - recall_m: 0.5316 - dice_coef_loss: 0.3903 - val_loss: 0.5780 - val_acc: 0.6744 - val_f1_m: 0.6136 - val_precision_m: 0.7550 - val_recall_m: 0.5173 - val_dice_coef_loss: 0.4137\n",
      "Epoch 39/150\n",
      "8/8 [==============================] - 33s 4s/step - loss: 0.5478 - acc: 0.7116 - f1_m: 0.6814 - precision_m: 0.7719 - recall_m: 0.6259 - dice_coef_loss: 0.3690 - val_loss: 0.6085 - val_acc: 0.6585 - val_f1_m: 0.6554 - val_precision_m: 0.6598 - val_recall_m: 0.6513 - val_dice_coef_loss: 0.3779\n",
      "Epoch 40/150\n",
      "8/8 [==============================] - 36s 4s/step - loss: 0.5256 - acc: 0.7093 - f1_m: 0.6987 - precision_m: 0.7839 - recall_m: 0.6350 - dice_coef_loss: 0.3447 - val_loss: 0.5821 - val_acc: 0.6803 - val_f1_m: 0.6500 - val_precision_m: 0.7173 - val_recall_m: 0.5947 - val_dice_coef_loss: 0.3908\n",
      "Epoch 41/150\n",
      "8/8 [==============================] - 33s 4s/step - loss: 0.5141 - acc: 0.7370 - f1_m: 0.7060 - precision_m: 0.7722 - recall_m: 0.6570 - dice_coef_loss: 0.3554 - val_loss: 0.5912 - val_acc: 0.6715 - val_f1_m: 0.6602 - val_precision_m: 0.6815 - val_recall_m: 0.6408 - val_dice_coef_loss: 0.3837\n",
      "Epoch 42/150\n",
      "8/8 [==============================] - 36s 5s/step - loss: 0.5116 - acc: 0.7280 - f1_m: 0.7120 - precision_m: 0.7793 - recall_m: 0.6625 - dice_coef_loss: 0.3415 - val_loss: 0.6077 - val_acc: 0.6758 - val_f1_m: 0.6580 - val_precision_m: 0.6955 - val_recall_m: 0.6257 - val_dice_coef_loss: 0.3870\n",
      "Epoch 43/150\n",
      "8/8 [==============================] - 37s 5s/step - loss: 0.5188 - acc: 0.7283 - f1_m: 0.6987 - precision_m: 0.7742 - recall_m: 0.6408 - dice_coef_loss: 0.3548 - val_loss: 0.5528 - val_acc: 0.6851 - val_f1_m: 0.6377 - val_precision_m: 0.7500 - val_recall_m: 0.5557 - val_dice_coef_loss: 0.3974\n",
      "Epoch 44/150\n",
      "8/8 [==============================] - 36s 4s/step - loss: 0.5180 - acc: 0.7291 - f1_m: 0.7201 - precision_m: 0.7624 - recall_m: 0.6904 - dice_coef_loss: 0.3422 - val_loss: 0.5667 - val_acc: 0.6818 - val_f1_m: 0.6717 - val_precision_m: 0.6907 - val_recall_m: 0.6545 - val_dice_coef_loss: 0.3810\n",
      "Epoch 45/150\n",
      "8/8 [==============================] - 32s 4s/step - loss: 0.5160 - acc: 0.7211 - f1_m: 0.7077 - precision_m: 0.7692 - recall_m: 0.6654 - dice_coef_loss: 0.3505 - val_loss: 0.6026 - val_acc: 0.6744 - val_f1_m: 0.6705 - val_precision_m: 0.6760 - val_recall_m: 0.6660 - val_dice_coef_loss: 0.3790\n",
      "Epoch 46/150\n",
      "8/8 [==============================] - 34s 4s/step - loss: 0.5046 - acc: 0.7405 - f1_m: 0.7161 - precision_m: 0.7951 - recall_m: 0.6536 - dice_coef_loss: 0.3450 - val_loss: 0.5705 - val_acc: 0.6876 - val_f1_m: 0.6661 - val_precision_m: 0.7142 - val_recall_m: 0.6248 - val_dice_coef_loss: 0.3793\n",
      "Epoch 47/150\n",
      "8/8 [==============================] - 38s 5s/step - loss: 0.4940 - acc: 0.7439 - f1_m: 0.7438 - precision_m: 0.7751 - recall_m: 0.7192 - dice_coef_loss: 0.3229 - val_loss: 0.5474 - val_acc: 0.6988 - val_f1_m: 0.6662 - val_precision_m: 0.7465 - val_recall_m: 0.6024 - val_dice_coef_loss: 0.3757\n",
      "Epoch 48/150\n",
      "8/8 [==============================] - 31s 4s/step - loss: 0.4709 - acc: 0.7558 - f1_m: 0.7251 - precision_m: 0.7939 - recall_m: 0.6686 - dice_coef_loss: 0.3223 - val_loss: 0.5399 - val_acc: 0.7121 - val_f1_m: 0.6977 - val_precision_m: 0.7350 - val_recall_m: 0.6651 - val_dice_coef_loss: 0.3467\n",
      "Epoch 49/150\n",
      "8/8 [==============================] - 36s 4s/step - loss: 0.4857 - acc: 0.7582 - f1_m: 0.7491 - precision_m: 0.7928 - recall_m: 0.7142 - dice_coef_loss: 0.3275 - val_loss: 0.5821 - val_acc: 0.7126 - val_f1_m: 0.7240 - val_precision_m: 0.6949 - val_recall_m: 0.7570 - val_dice_coef_loss: 0.3461\n",
      "Epoch 50/150\n",
      "8/8 [==============================] - 35s 4s/step - loss: 0.4727 - acc: 0.7687 - f1_m: 0.7739 - precision_m: 0.7696 - recall_m: 0.7885 - dice_coef_loss: 0.3070 - val_loss: 0.5073 - val_acc: 0.7488 - val_f1_m: 0.7361 - val_precision_m: 0.7757 - val_recall_m: 0.7008 - val_dice_coef_loss: 0.3562\n",
      "Epoch 51/150\n",
      "8/8 [==============================] - 35s 4s/step - loss: 0.4456 - acc: 0.7868 - f1_m: 0.7818 - precision_m: 0.7978 - recall_m: 0.7723 - dice_coef_loss: 0.2960 - val_loss: 0.5125 - val_acc: 0.7531 - val_f1_m: 0.7544 - val_precision_m: 0.7531 - val_recall_m: 0.7569 - val_dice_coef_loss: 0.3205\n",
      "Epoch 52/150\n",
      "8/8 [==============================] - 35s 4s/step - loss: 0.4199 - acc: 0.8018 - f1_m: 0.8105 - precision_m: 0.8009 - recall_m: 0.8231 - dice_coef_loss: 0.2723 - val_loss: 0.5222 - val_acc: 0.7568 - val_f1_m: 0.7554 - val_precision_m: 0.7609 - val_recall_m: 0.7513 - val_dice_coef_loss: 0.3079\n",
      "Epoch 53/150\n",
      "8/8 [==============================] - 32s 4s/step - loss: 0.4309 - acc: 0.7976 - f1_m: 0.7997 - precision_m: 0.7975 - recall_m: 0.8074 - dice_coef_loss: 0.2664 - val_loss: 0.4539 - val_acc: 0.7913 - val_f1_m: 0.7945 - val_precision_m: 0.7859 - val_recall_m: 0.8046 - val_dice_coef_loss: 0.3070\n",
      "Epoch 54/150\n",
      "8/8 [==============================] - 37s 5s/step - loss: 0.4159 - acc: 0.8120 - f1_m: 0.8120 - precision_m: 0.8283 - recall_m: 0.7998 - dice_coef_loss: 0.2749 - val_loss: 0.4732 - val_acc: 0.7796 - val_f1_m: 0.7861 - val_precision_m: 0.7673 - val_recall_m: 0.8073 - val_dice_coef_loss: 0.2738\n",
      "Epoch 55/150\n",
      "8/8 [==============================] - 34s 4s/step - loss: 0.4007 - acc: 0.8153 - f1_m: 0.8241 - precision_m: 0.8379 - recall_m: 0.8198 - dice_coef_loss: 0.2405 - val_loss: 0.4763 - val_acc: 0.7720 - val_f1_m: 0.7544 - val_precision_m: 0.8211 - val_recall_m: 0.6986 - val_dice_coef_loss: 0.3276\n",
      "Epoch 56/150\n",
      "8/8 [==============================] - 39s 5s/step - loss: 0.3940 - acc: 0.8217 - f1_m: 0.8225 - precision_m: 0.8303 - recall_m: 0.8240 - dice_coef_loss: 0.2574 - val_loss: 0.5219 - val_acc: 0.7257 - val_f1_m: 0.7631 - val_precision_m: 0.6708 - val_recall_m: 0.8869 - val_dice_coef_loss: 0.2880\n",
      "Epoch 57/150\n",
      "8/8 [==============================] - 33s 4s/step - loss: 0.4044 - acc: 0.8121 - f1_m: 0.8020 - precision_m: 0.8078 - recall_m: 0.8138 - dice_coef_loss: 0.2657 - val_loss: 0.4745 - val_acc: 0.7803 - val_f1_m: 0.7883 - val_precision_m: 0.7629 - val_recall_m: 0.8170 - val_dice_coef_loss: 0.2891\n",
      "Epoch 58/150\n",
      "8/8 [==============================] - 36s 4s/step - loss: 0.3754 - acc: 0.8283 - f1_m: 0.8343 - precision_m: 0.8388 - recall_m: 0.8335 - dice_coef_loss: 0.2381 - val_loss: 0.4305 - val_acc: 0.8020 - val_f1_m: 0.8032 - val_precision_m: 0.8047 - val_recall_m: 0.8031 - val_dice_coef_loss: 0.2685\n",
      "Epoch 59/150\n",
      "8/8 [==============================] - 31s 4s/step - loss: 0.3617 - acc: 0.8319 - f1_m: 0.8405 - precision_m: 0.8474 - recall_m: 0.8355 - dice_coef_loss: 0.2219 - val_loss: 0.3997 - val_acc: 0.8156 - val_f1_m: 0.8203 - val_precision_m: 0.8054 - val_recall_m: 0.8366 - val_dice_coef_loss: 0.2564\n",
      "Epoch 60/150\n",
      "8/8 [==============================] - 37s 5s/step - loss: 0.3519 - acc: 0.8439 - f1_m: 0.8442 - precision_m: 0.8528 - recall_m: 0.8407 - dice_coef_loss: 0.2275 - val_loss: 0.4533 - val_acc: 0.7930 - val_f1_m: 0.8140 - val_precision_m: 0.7425 - val_recall_m: 0.9022 - val_dice_coef_loss: 0.2320\n",
      "Epoch 61/150\n",
      "8/8 [==============================] - 36s 4s/step - loss: 0.3367 - acc: 0.8475 - f1_m: 0.8410 - precision_m: 0.8436 - recall_m: 0.8411 - dice_coef_loss: 0.2224 - val_loss: 0.4599 - val_acc: 0.7928 - val_f1_m: 0.7739 - val_precision_m: 0.8635 - val_recall_m: 0.7034 - val_dice_coef_loss: 0.2884\n",
      "Epoch 62/150\n",
      "8/8 [==============================] - 36s 5s/step - loss: 0.3227 - acc: 0.8525 - f1_m: 0.8615 - precision_m: 0.8566 - recall_m: 0.8713 - dice_coef_loss: 0.1985 - val_loss: 0.4235 - val_acc: 0.8118 - val_f1_m: 0.8022 - val_precision_m: 0.8571 - val_recall_m: 0.7560 - val_dice_coef_loss: 0.2543\n",
      "Epoch 63/150\n",
      "8/8 [==============================] - 33s 4s/step - loss: 0.3350 - acc: 0.8470 - f1_m: 0.8521 - precision_m: 0.8568 - recall_m: 0.8498 - dice_coef_loss: 0.2055 - val_loss: 0.4037 - val_acc: 0.8171 - val_f1_m: 0.8187 - val_precision_m: 0.8225 - val_recall_m: 0.8158 - val_dice_coef_loss: 0.2451\n",
      "Epoch 64/150\n",
      "8/8 [==============================] - 35s 4s/step - loss: 0.3255 - acc: 0.8510 - f1_m: 0.8516 - precision_m: 0.8665 - recall_m: 0.8401 - dice_coef_loss: 0.2109 - val_loss: 0.3985 - val_acc: 0.8178 - val_f1_m: 0.8237 - val_precision_m: 0.8035 - val_recall_m: 0.8456 - val_dice_coef_loss: 0.2451\n",
      "Epoch 65/150\n",
      "8/8 [==============================] - 36s 4s/step - loss: 0.3413 - acc: 0.8470 - f1_m: 0.8518 - precision_m: 0.8651 - recall_m: 0.8427 - dice_coef_loss: 0.2158 - val_loss: 0.4378 - val_acc: 0.7974 - val_f1_m: 0.8173 - val_precision_m: 0.7461 - val_recall_m: 0.9043 - val_dice_coef_loss: 0.2414\n",
      "Epoch 66/150\n",
      "8/8 [==============================] - 35s 4s/step - loss: 0.3380 - acc: 0.8444 - f1_m: 0.8500 - precision_m: 0.8371 - recall_m: 0.8693 - dice_coef_loss: 0.2035 - val_loss: 0.4018 - val_acc: 0.8155 - val_f1_m: 0.8204 - val_precision_m: 0.8058 - val_recall_m: 0.8368 - val_dice_coef_loss: 0.2416\n",
      "Epoch 67/150\n",
      "8/8 [==============================] - 34s 4s/step - loss: 0.2848 - acc: 0.8699 - f1_m: 0.8682 - precision_m: 0.8819 - recall_m: 0.8554 - dice_coef_loss: 0.1904 - val_loss: 0.4079 - val_acc: 0.8131 - val_f1_m: 0.8151 - val_precision_m: 0.8146 - val_recall_m: 0.8174 - val_dice_coef_loss: 0.2379\n",
      "Epoch 68/150\n",
      "8/8 [==============================] - 35s 4s/step - loss: 0.3111 - acc: 0.8590 - f1_m: 0.8644 - precision_m: 0.8687 - recall_m: 0.8616 - dice_coef_loss: 0.1882 - val_loss: 0.3874 - val_acc: 0.8245 - val_f1_m: 0.8330 - val_precision_m: 0.7992 - val_recall_m: 0.8708 - val_dice_coef_loss: 0.2271\n",
      "Epoch 69/150\n",
      "8/8 [==============================] - 39s 5s/step - loss: 0.2801 - acc: 0.8743 - f1_m: 0.8798 - precision_m: 0.8870 - recall_m: 0.8748 - dice_coef_loss: 0.1750 - val_loss: 0.3925 - val_acc: 0.8276 - val_f1_m: 0.8368 - val_precision_m: 0.8030 - val_recall_m: 0.8741 - val_dice_coef_loss: 0.2142\n",
      "Epoch 70/150\n",
      "8/8 [==============================] - 36s 4s/step - loss: 0.2443 - acc: 0.8889 - f1_m: 0.8899 - precision_m: 0.8948 - recall_m: 0.8864 - dice_coef_loss: 0.1581 - val_loss: 0.3804 - val_acc: 0.8323 - val_f1_m: 0.8433 - val_precision_m: 0.7994 - val_recall_m: 0.8928 - val_dice_coef_loss: 0.2003\n",
      "Epoch 71/150\n",
      "8/8 [==============================] - 50s 6s/step - loss: 0.2791 - acc: 0.8720 - f1_m: 0.8782 - precision_m: 0.8803 - recall_m: 0.8797 - dice_coef_loss: 0.1693 - val_loss: 0.4250 - val_acc: 0.8154 - val_f1_m: 0.8316 - val_precision_m: 0.7694 - val_recall_m: 0.9062 - val_dice_coef_loss: 0.2268\n",
      "Epoch 72/150\n",
      "8/8 [==============================] - 50s 6s/step - loss: 0.2654 - acc: 0.8821 - f1_m: 0.8834 - precision_m: 0.8899 - recall_m: 0.8805 - dice_coef_loss: 0.1699 - val_loss: 0.3908 - val_acc: 0.8299 - val_f1_m: 0.8362 - val_precision_m: 0.8142 - val_recall_m: 0.8601 - val_dice_coef_loss: 0.2063\n",
      "Epoch 73/150\n",
      "8/8 [==============================] - 72s 9s/step - loss: 0.2678 - acc: 0.8794 - f1_m: 0.8815 - precision_m: 0.8897 - recall_m: 0.8750 - dice_coef_loss: 0.1706 - val_loss: 0.3878 - val_acc: 0.8265 - val_f1_m: 0.8196 - val_precision_m: 0.8671 - val_recall_m: 0.7774 - val_dice_coef_loss: 0.2324\n",
      "Epoch 74/150\n",
      "8/8 [==============================] - 79s 10s/step - loss: 0.2649 - acc: 0.8792 - f1_m: 0.8887 - precision_m: 0.8820 - recall_m: 0.8996 - dice_coef_loss: 0.1546 - val_loss: 0.3864 - val_acc: 0.8340 - val_f1_m: 0.8334 - val_precision_m: 0.8464 - val_recall_m: 0.8214 - val_dice_coef_loss: 0.2165\n",
      "Epoch 75/150\n",
      "8/8 [==============================] - 79s 10s/step - loss: 0.2648 - acc: 0.8777 - f1_m: 0.8814 - precision_m: 0.8938 - recall_m: 0.8755 - dice_coef_loss: 0.1676 - val_loss: 0.3641 - val_acc: 0.8367 - val_f1_m: 0.8312 - val_precision_m: 0.8747 - val_recall_m: 0.7937 - val_dice_coef_loss: 0.2151\n",
      "Epoch 76/150\n",
      "8/8 [==============================] - 79s 10s/step - loss: 0.2269 - acc: 0.8982 - f1_m: 0.8990 - precision_m: 0.9115 - recall_m: 0.8879 - dice_coef_loss: 0.1507 - val_loss: 0.4098 - val_acc: 0.8209 - val_f1_m: 0.8342 - val_precision_m: 0.7839 - val_recall_m: 0.8925 - val_dice_coef_loss: 0.2072\n",
      "Epoch 77/150\n",
      "8/8 [==============================] - 84s 10s/step - loss: 0.2310 - acc: 0.8944 - f1_m: 0.8984 - precision_m: 0.8997 - recall_m: 0.8986 - dice_coef_loss: 0.1436 - val_loss: 0.3671 - val_acc: 0.8415 - val_f1_m: 0.8441 - val_precision_m: 0.8433 - val_recall_m: 0.8462 - val_dice_coef_loss: 0.1937\n",
      "Epoch 78/150\n",
      "8/8 [==============================] - 84s 10s/step - loss: 0.2199 - acc: 0.9005 - f1_m: 0.9100 - precision_m: 0.9109 - recall_m: 0.9097 - dice_coef_loss: 0.1306 - val_loss: 0.4342 - val_acc: 0.8212 - val_f1_m: 0.8333 - val_precision_m: 0.7874 - val_recall_m: 0.8858 - val_dice_coef_loss: 0.1978\n",
      "Epoch 79/150\n",
      "8/8 [==============================] - 84s 11s/step - loss: 0.1998 - acc: 0.9085 - f1_m: 0.9115 - precision_m: 0.9093 - recall_m: 0.9146 - dice_coef_loss: 0.1214 - val_loss: 0.3901 - val_acc: 0.8293 - val_f1_m: 0.8409 - val_precision_m: 0.7955 - val_recall_m: 0.8922 - val_dice_coef_loss: 0.1941\n",
      "Epoch 80/150\n",
      "8/8 [==============================] - 78s 10s/step - loss: 0.1715 - acc: 0.9226 - f1_m: 0.9258 - precision_m: 0.9254 - recall_m: 0.9270 - dice_coef_loss: 0.1106 - val_loss: 0.4263 - val_acc: 0.8308 - val_f1_m: 0.8371 - val_precision_m: 0.8182 - val_recall_m: 0.8581 - val_dice_coef_loss: 0.1914\n",
      "Epoch 81/150\n",
      "8/8 [==============================] - 85s 11s/step - loss: 0.1766 - acc: 0.9186 - f1_m: 0.9252 - precision_m: 0.9294 - recall_m: 0.9219 - dice_coef_loss: 0.1052 - val_loss: 0.3777 - val_acc: 0.8473 - val_f1_m: 0.8482 - val_precision_m: 0.8578 - val_recall_m: 0.8392 - val_dice_coef_loss: 0.1837\n",
      "Epoch 82/150\n",
      "8/8 [==============================] - 77s 10s/step - loss: 0.1811 - acc: 0.9172 - f1_m: 0.9218 - precision_m: 0.9220 - recall_m: 0.9239 - dice_coef_loss: 0.1134 - val_loss: 0.4815 - val_acc: 0.8071 - val_f1_m: 0.8216 - val_precision_m: 0.7700 - val_recall_m: 0.8812 - val_dice_coef_loss: 0.2071\n",
      "Epoch 83/150\n",
      "8/8 [==============================] - 82s 10s/step - loss: 0.2182 - acc: 0.9025 - f1_m: 0.9106 - precision_m: 0.9177 - recall_m: 0.9071 - dice_coef_loss: 0.1239 - val_loss: 0.3990 - val_acc: 0.8249 - val_f1_m: 0.8134 - val_precision_m: 0.8886 - val_recall_m: 0.7513 - val_dice_coef_loss: 0.2212\n",
      "Epoch 84/150\n",
      "8/8 [==============================] - 80s 10s/step - loss: 0.1981 - acc: 0.9115 - f1_m: 0.9077 - precision_m: 0.9243 - recall_m: 0.8935 - dice_coef_loss: 0.1337 - val_loss: 0.3748 - val_acc: 0.8472 - val_f1_m: 0.8528 - val_precision_m: 0.8368 - val_recall_m: 0.8705 - val_dice_coef_loss: 0.1771\n",
      "Epoch 85/150\n",
      "8/8 [==============================] - 83s 10s/step - loss: 0.1917 - acc: 0.9123 - f1_m: 0.9249 - precision_m: 0.9261 - recall_m: 0.9245 - dice_coef_loss: 0.1070 - val_loss: 0.3978 - val_acc: 0.8386 - val_f1_m: 0.8425 - val_precision_m: 0.8372 - val_recall_m: 0.8489 - val_dice_coef_loss: 0.1851\n",
      "Epoch 86/150\n",
      "8/8 [==============================] - 87s 11s/step - loss: 0.1620 - acc: 0.9275 - f1_m: 0.9303 - precision_m: 0.9382 - recall_m: 0.9234 - dice_coef_loss: 0.1015 - val_loss: 0.3933 - val_acc: 0.8374 - val_f1_m: 0.8463 - val_precision_m: 0.8123 - val_recall_m: 0.8840 - val_dice_coef_loss: 0.1808\n",
      "Epoch 87/150\n",
      "8/8 [==============================] - 80s 10s/step - loss: 0.1585 - acc: 0.9272 - f1_m: 0.9286 - precision_m: 0.9253 - recall_m: 0.9328 - dice_coef_loss: 0.1034 - val_loss: 0.4367 - val_acc: 0.8354 - val_f1_m: 0.8421 - val_precision_m: 0.8205 - val_recall_m: 0.8665 - val_dice_coef_loss: 0.1800\n",
      "Epoch 88/150\n",
      "8/8 [==============================] - 80s 10s/step - loss: 0.1613 - acc: 0.9255 - f1_m: 0.9342 - precision_m: 0.9328 - recall_m: 0.9361 - dice_coef_loss: 0.0913 - val_loss: 0.3848 - val_acc: 0.8475 - val_f1_m: 0.8478 - val_precision_m: 0.8594 - val_recall_m: 0.8373 - val_dice_coef_loss: 0.1794\n",
      "Epoch 89/150\n",
      "8/8 [==============================] - 82s 10s/step - loss: 0.1568 - acc: 0.9293 - f1_m: 0.9334 - precision_m: 0.9442 - recall_m: 0.9234 - dice_coef_loss: 0.0995 - val_loss: 0.4067 - val_acc: 0.8391 - val_f1_m: 0.8464 - val_precision_m: 0.8225 - val_recall_m: 0.8729 - val_dice_coef_loss: 0.1770\n",
      "Epoch 90/150\n",
      "8/8 [==============================] - 82s 10s/step - loss: 0.1366 - acc: 0.9368 - f1_m: 0.9416 - precision_m: 0.9384 - recall_m: 0.9456 - dice_coef_loss: 0.0827 - val_loss: 0.4306 - val_acc: 0.8427 - val_f1_m: 0.8482 - val_precision_m: 0.8344 - val_recall_m: 0.8632 - val_dice_coef_loss: 0.1711\n",
      "Epoch 91/150\n",
      "8/8 [==============================] - 81s 10s/step - loss: 0.1281 - acc: 0.9395 - f1_m: 0.9467 - precision_m: 0.9491 - recall_m: 0.9447 - dice_coef_loss: 0.0763 - val_loss: 0.4282 - val_acc: 0.8394 - val_f1_m: 0.8339 - val_precision_m: 0.8805 - val_recall_m: 0.7927 - val_dice_coef_loss: 0.1862\n",
      "Epoch 92/150\n",
      "8/8 [==============================] - 76s 10s/step - loss: 0.1165 - acc: 0.9451 - f1_m: 0.9479 - precision_m: 0.9523 - recall_m: 0.9439 - dice_coef_loss: 0.0745 - val_loss: 0.4384 - val_acc: 0.8502 - val_f1_m: 0.8564 - val_precision_m: 0.8385 - val_recall_m: 0.8759 - val_dice_coef_loss: 0.1594\n",
      "Epoch 93/150\n",
      "8/8 [==============================] - 83s 10s/step - loss: 0.1132 - acc: 0.9474 - f1_m: 0.9539 - precision_m: 0.9544 - recall_m: 0.9535 - dice_coef_loss: 0.0655 - val_loss: 0.4792 - val_acc: 0.8365 - val_f1_m: 0.8466 - val_precision_m: 0.8085 - val_recall_m: 0.8892 - val_dice_coef_loss: 0.1694\n",
      "Epoch 94/150\n",
      "8/8 [==============================] - 82s 10s/step - loss: 0.1060 - acc: 0.9483 - f1_m: 0.9535 - precision_m: 0.9507 - recall_m: 0.9567 - dice_coef_loss: 0.0655 - val_loss: 0.4911 - val_acc: 0.8454 - val_f1_m: 0.8436 - val_precision_m: 0.8729 - val_recall_m: 0.8169 - val_dice_coef_loss: 0.1700\n",
      "Epoch 95/150\n",
      "8/8 [==============================] - 81s 10s/step - loss: 0.0961 - acc: 0.9532 - f1_m: 0.9582 - precision_m: 0.9629 - recall_m: 0.9539 - dice_coef_loss: 0.0574 - val_loss: 0.4676 - val_acc: 0.8470 - val_f1_m: 0.8523 - val_precision_m: 0.8405 - val_recall_m: 0.8647 - val_dice_coef_loss: 0.1616\n",
      "Epoch 96/150\n",
      "8/8 [==============================] - 79s 10s/step - loss: 0.0868 - acc: 0.9571 - f1_m: 0.9599 - precision_m: 0.9614 - recall_m: 0.9585 - dice_coef_loss: 0.0565 - val_loss: 0.5363 - val_acc: 0.8401 - val_f1_m: 0.8481 - val_precision_m: 0.8201 - val_recall_m: 0.8785 - val_dice_coef_loss: 0.1644\n",
      "Epoch 97/150\n",
      "8/8 [==============================] - 77s 10s/step - loss: 0.0924 - acc: 0.9530 - f1_m: 0.9616 - precision_m: 0.9569 - recall_m: 0.9665 - dice_coef_loss: 0.0530 - val_loss: 0.5141 - val_acc: 0.8472 - val_f1_m: 0.8491 - val_precision_m: 0.8581 - val_recall_m: 0.8412 - val_dice_coef_loss: 0.1635\n",
      "Epoch 98/150\n",
      "8/8 [==============================] - 87s 11s/step - loss: 0.0863 - acc: 0.9575 - f1_m: 0.9607 - precision_m: 0.9626 - recall_m: 0.9588 - dice_coef_loss: 0.0540 - val_loss: 0.5448 - val_acc: 0.8432 - val_f1_m: 0.8486 - val_precision_m: 0.8339 - val_recall_m: 0.8644 - val_dice_coef_loss: 0.1633\n",
      "Epoch 99/150\n",
      "8/8 [==============================] - 83s 10s/step - loss: 0.0836 - acc: 0.9576 - f1_m: 0.9640 - precision_m: 0.9647 - recall_m: 0.9633 - dice_coef_loss: 0.0495 - val_loss: 0.5525 - val_acc: 0.8446 - val_f1_m: 0.8510 - val_precision_m: 0.8342 - val_recall_m: 0.8692 - val_dice_coef_loss: 0.1592\n",
      "Epoch 100/150\n",
      "8/8 [==============================] - 79s 10s/step - loss: 0.0800 - acc: 0.9594 - f1_m: 0.9640 - precision_m: 0.9633 - recall_m: 0.9648 - dice_coef_loss: 0.0499 - val_loss: 0.5832 - val_acc: 0.8354 - val_f1_m: 0.8458 - val_precision_m: 0.8077 - val_recall_m: 0.8880 - val_dice_coef_loss: 0.1652\n",
      "Epoch 101/150\n",
      "8/8 [==============================] - 81s 10s/step - loss: 0.0785 - acc: 0.9593 - f1_m: 0.9652 - precision_m: 0.9633 - recall_m: 0.9673 - dice_coef_loss: 0.0472 - val_loss: 0.6079 - val_acc: 0.8516 - val_f1_m: 0.8518 - val_precision_m: 0.8739 - val_recall_m: 0.8313 - val_dice_coef_loss: 0.1571\n",
      "Epoch 102/150\n",
      "8/8 [==============================] - 82s 10s/step - loss: 0.0830 - acc: 0.9580 - f1_m: 0.9641 - precision_m: 0.9666 - recall_m: 0.9619 - dice_coef_loss: 0.0494 - val_loss: 0.5472 - val_acc: 0.8430 - val_f1_m: 0.8415 - val_precision_m: 0.8681 - val_recall_m: 0.8169 - val_dice_coef_loss: 0.1705\n",
      "Epoch 103/150\n",
      "8/8 [==============================] - 86s 11s/step - loss: 0.0817 - acc: 0.9583 - f1_m: 0.9645 - precision_m: 0.9651 - recall_m: 0.9640 - dice_coef_loss: 0.0486 - val_loss: 0.5892 - val_acc: 0.8420 - val_f1_m: 0.8519 - val_precision_m: 0.8166 - val_recall_m: 0.8912 - val_dice_coef_loss: 0.1572\n",
      "Epoch 104/150\n",
      "8/8 [==============================] - 77s 10s/step - loss: 0.0833 - acc: 0.9576 - f1_m: 0.9620 - precision_m: 0.9593 - recall_m: 0.9652 - dice_coef_loss: 0.0508 - val_loss: 0.7208 - val_acc: 0.8167 - val_f1_m: 0.8334 - val_precision_m: 0.7727 - val_recall_m: 0.9048 - val_dice_coef_loss: 0.1753\n",
      "Epoch 105/150\n",
      "8/8 [==============================] - 82s 10s/step - loss: 0.1092 - acc: 0.9483 - f1_m: 0.9522 - precision_m: 0.9551 - recall_m: 0.9501 - dice_coef_loss: 0.0680 - val_loss: 0.5311 - val_acc: 0.8387 - val_f1_m: 0.8401 - val_precision_m: 0.8467 - val_recall_m: 0.8341 - val_dice_coef_loss: 0.1755\n",
      "Epoch 106/150\n",
      "8/8 [==============================] - 88s 11s/step - loss: 0.1082 - acc: 0.9489 - f1_m: 0.9543 - precision_m: 0.9578 - recall_m: 0.9512 - dice_coef_loss: 0.0649 - val_loss: 0.5822 - val_acc: 0.8390 - val_f1_m: 0.8370 - val_precision_m: 0.8647 - val_recall_m: 0.8117 - val_dice_coef_loss: 0.1764\n",
      "Epoch 107/150\n",
      "8/8 [==============================] - 80s 10s/step - loss: 0.0939 - acc: 0.9534 - f1_m: 0.9597 - precision_m: 0.9569 - recall_m: 0.9626 - dice_coef_loss: 0.0559 - val_loss: 0.4987 - val_acc: 0.8449 - val_f1_m: 0.8522 - val_precision_m: 0.8307 - val_recall_m: 0.8753 - val_dice_coef_loss: 0.1618\n",
      "Epoch 108/150\n",
      "8/8 [==============================] - 82s 10s/step - loss: 0.0859 - acc: 0.9572 - f1_m: 0.9618 - precision_m: 0.9600 - recall_m: 0.9638 - dice_coef_loss: 0.0532 - val_loss: 0.5756 - val_acc: 0.8406 - val_f1_m: 0.8427 - val_precision_m: 0.8487 - val_recall_m: 0.8372 - val_dice_coef_loss: 0.1684\n",
      "Epoch 109/150\n",
      "8/8 [==============================] - 81s 10s/step - loss: 0.0841 - acc: 0.9573 - f1_m: 0.9619 - precision_m: 0.9617 - recall_m: 0.9625 - dice_coef_loss: 0.0521 - val_loss: 0.6310 - val_acc: 0.8420 - val_f1_m: 0.8370 - val_precision_m: 0.8838 - val_recall_m: 0.7956 - val_dice_coef_loss: 0.1737\n",
      "Epoch 110/150\n",
      "8/8 [==============================] - 87s 11s/step - loss: 0.0835 - acc: 0.9593 - f1_m: 0.9640 - precision_m: 0.9662 - recall_m: 0.9619 - dice_coef_loss: 0.0492 - val_loss: 0.5103 - val_acc: 0.8493 - val_f1_m: 0.8556 - val_precision_m: 0.8382 - val_recall_m: 0.8744 - val_dice_coef_loss: 0.1558\n",
      "Epoch 111/150\n",
      "8/8 [==============================] - 83s 10s/step - loss: 0.0784 - acc: 0.9593 - f1_m: 0.9648 - precision_m: 0.9671 - recall_m: 0.9626 - dice_coef_loss: 0.0485 - val_loss: 0.5813 - val_acc: 0.8396 - val_f1_m: 0.8457 - val_precision_m: 0.8290 - val_recall_m: 0.8637 - val_dice_coef_loss: 0.1632\n",
      "Epoch 112/150\n",
      "8/8 [==============================] - 76s 10s/step - loss: 0.0676 - acc: 0.9647 - f1_m: 0.9701 - precision_m: 0.9690 - recall_m: 0.9714 - dice_coef_loss: 0.0410 - val_loss: 0.6048 - val_acc: 0.8440 - val_f1_m: 0.8495 - val_precision_m: 0.8372 - val_recall_m: 0.8630 - val_dice_coef_loss: 0.1589\n",
      "Epoch 113/150\n",
      "8/8 [==============================] - 87s 11s/step - loss: 0.0689 - acc: 0.9640 - f1_m: 0.9693 - precision_m: 0.9680 - recall_m: 0.9706 - dice_coef_loss: 0.0420 - val_loss: 0.6146 - val_acc: 0.8458 - val_f1_m: 0.8485 - val_precision_m: 0.8517 - val_recall_m: 0.8456 - val_dice_coef_loss: 0.1597\n",
      "Epoch 114/150\n",
      "8/8 [==============================] - 83s 10s/step - loss: 0.0643 - acc: 0.9651 - f1_m: 0.9705 - precision_m: 0.9707 - recall_m: 0.9703 - dice_coef_loss: 0.0392 - val_loss: 0.6453 - val_acc: 0.8504 - val_f1_m: 0.8518 - val_precision_m: 0.8653 - val_recall_m: 0.8394 - val_dice_coef_loss: 0.1551\n",
      "Epoch 115/150\n",
      "8/8 [==============================] - 84s 11s/step - loss: 0.0613 - acc: 0.9659 - f1_m: 0.9716 - precision_m: 0.9719 - recall_m: 0.9713 - dice_coef_loss: 0.0383 - val_loss: 0.6353 - val_acc: 0.8479 - val_f1_m: 0.8509 - val_precision_m: 0.8532 - val_recall_m: 0.8490 - val_dice_coef_loss: 0.1563\n",
      "Epoch 116/150\n",
      "8/8 [==============================] - 81s 10s/step - loss: 0.0577 - acc: 0.9679 - f1_m: 0.9727 - precision_m: 0.9733 - recall_m: 0.9721 - dice_coef_loss: 0.0358 - val_loss: 0.7303 - val_acc: 0.8453 - val_f1_m: 0.8480 - val_precision_m: 0.8533 - val_recall_m: 0.8431 - val_dice_coef_loss: 0.1578\n",
      "Epoch 117/150\n",
      "8/8 [==============================] - 82s 10s/step - loss: 0.0557 - acc: 0.9686 - f1_m: 0.9739 - precision_m: 0.9731 - recall_m: 0.9748 - dice_coef_loss: 0.0347 - val_loss: 0.7247 - val_acc: 0.8441 - val_f1_m: 0.8472 - val_precision_m: 0.8490 - val_recall_m: 0.8458 - val_dice_coef_loss: 0.1585\n",
      "Epoch 118/150\n",
      "8/8 [==============================] - 84s 11s/step - loss: 0.0547 - acc: 0.9691 - f1_m: 0.9746 - precision_m: 0.9749 - recall_m: 0.9743 - dice_coef_loss: 0.0332 - val_loss: 0.7193 - val_acc: 0.8468 - val_f1_m: 0.8525 - val_precision_m: 0.8400 - val_recall_m: 0.8659 - val_dice_coef_loss: 0.1526\n",
      "Epoch 119/150\n",
      "8/8 [==============================] - 82s 10s/step - loss: 0.0525 - acc: 0.9698 - f1_m: 0.9754 - precision_m: 0.9749 - recall_m: 0.9759 - dice_coef_loss: 0.0323 - val_loss: 0.7565 - val_acc: 0.8452 - val_f1_m: 0.8486 - val_precision_m: 0.8498 - val_recall_m: 0.8479 - val_dice_coef_loss: 0.1563\n",
      "Epoch 120/150\n",
      "8/8 [==============================] - 87s 11s/step - loss: 0.0507 - acc: 0.9711 - f1_m: 0.9762 - precision_m: 0.9763 - recall_m: 0.9761 - dice_coef_loss: 0.0316 - val_loss: 0.7796 - val_acc: 0.8486 - val_f1_m: 0.8537 - val_precision_m: 0.8455 - val_recall_m: 0.8628 - val_dice_coef_loss: 0.1506\n",
      "Epoch 121/150\n",
      "8/8 [==============================] - 76s 10s/step - loss: 0.0462 - acc: 0.9721 - f1_m: 0.9773 - precision_m: 0.9771 - recall_m: 0.9775 - dice_coef_loss: 0.0295 - val_loss: 0.8319 - val_acc: 0.8432 - val_f1_m: 0.8498 - val_precision_m: 0.8331 - val_recall_m: 0.8677 - val_dice_coef_loss: 0.1542\n",
      "Epoch 122/150\n",
      "8/8 [==============================] - 89s 11s/step - loss: 0.0490 - acc: 0.9715 - f1_m: 0.9775 - precision_m: 0.9770 - recall_m: 0.9781 - dice_coef_loss: 0.0293 - val_loss: 0.8514 - val_acc: 0.8454 - val_f1_m: 0.8483 - val_precision_m: 0.8534 - val_recall_m: 0.8437 - val_dice_coef_loss: 0.1556\n",
      "Epoch 123/150\n",
      "8/8 [==============================] - 74s 9s/step - loss: 0.0417 - acc: 0.9745 - f1_m: 0.9792 - precision_m: 0.9790 - recall_m: 0.9795 - dice_coef_loss: 0.0275 - val_loss: 0.8795 - val_acc: 0.8471 - val_f1_m: 0.8505 - val_precision_m: 0.8528 - val_recall_m: 0.8486 - val_dice_coef_loss: 0.1527\n",
      "Epoch 124/150\n",
      "8/8 [==============================] - 83s 10s/step - loss: 0.0449 - acc: 0.9732 - f1_m: 0.9791 - precision_m: 0.9798 - recall_m: 0.9785 - dice_coef_loss: 0.0265 - val_loss: 0.8798 - val_acc: 0.8445 - val_f1_m: 0.8475 - val_precision_m: 0.8517 - val_recall_m: 0.8440 - val_dice_coef_loss: 0.1563\n",
      "Epoch 125/150\n",
      "8/8 [==============================] - 88s 11s/step - loss: 0.0468 - acc: 0.9722 - f1_m: 0.9780 - precision_m: 0.9773 - recall_m: 0.9787 - dice_coef_loss: 0.0286 - val_loss: 0.9084 - val_acc: 0.8395 - val_f1_m: 0.8488 - val_precision_m: 0.8190 - val_recall_m: 0.8813 - val_dice_coef_loss: 0.1547\n",
      "Epoch 126/150\n",
      "8/8 [==============================] - 83s 10s/step - loss: 0.0527 - acc: 0.9701 - f1_m: 0.9755 - precision_m: 0.9731 - recall_m: 0.9781 - dice_coef_loss: 0.0313 - val_loss: 0.7674 - val_acc: 0.8433 - val_f1_m: 0.8402 - val_precision_m: 0.8793 - val_recall_m: 0.8048 - val_dice_coef_loss: 0.1655\n",
      "Epoch 127/150\n",
      "8/8 [==============================] - 79s 10s/step - loss: 0.0530 - acc: 0.9699 - f1_m: 0.9749 - precision_m: 0.9772 - recall_m: 0.9730 - dice_coef_loss: 0.0333 - val_loss: 0.7495 - val_acc: 0.8456 - val_f1_m: 0.8532 - val_precision_m: 0.8310 - val_recall_m: 0.8771 - val_dice_coef_loss: 0.1521\n",
      "Epoch 128/150\n",
      "8/8 [==============================] - 82s 10s/step - loss: 0.0560 - acc: 0.9684 - f1_m: 0.9754 - precision_m: 0.9758 - recall_m: 0.9751 - dice_coef_loss: 0.0326 - val_loss: 0.7513 - val_acc: 0.8424 - val_f1_m: 0.8465 - val_precision_m: 0.8425 - val_recall_m: 0.8509 - val_dice_coef_loss: 0.1584\n",
      "Epoch 129/150\n",
      "4/8 [==============>...............] - ETA: 38s - loss: 0.0496 - acc: 0.9719 - f1_m: 0.9744 - precision_m: 0.9733 - recall_m: 0.9757 - dice_coef_loss: 0.0345"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_data = DataGen(train_ids,batch_size=batch_size,image_size = image_size)\n",
    "valid_data = DataGen(test_ids,batch_size=batch_size,image_size = image_size)\n",
    "    \n",
    "train_steps= len(train_ids)//batch_size;\n",
    "valid_steps= len(test_ids)//batch_size;\n",
    "    \n",
    "epochs = 150;\n",
    "#model.load_weights(\"model_test_check.hdf5\")\n",
    "result = model.fit_generator(train_data, validation_data=valid_data, \n",
    "                                 steps_per_epoch=train_steps, \n",
    "                                 validation_steps=valid_steps, \n",
    "                                 epochs=epochs,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"unet.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"unet_history.json\",\"w\") as f:\n",
    "    json.dump(str(history),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
